#!/usr/bin/env python3
"""
Mapillary Dataset Downloader for WhereIsThisPlace
Downloads geolocated images from Mapillary API for training data.

Usage:
    python scripts/mapillary_downloader.py \
        --access-token YOUR_MAPILLARY_TOKEN \
        --bbox "2.2,48.8,2.4,48.9" \
        --output-dir ./datasets/mapillary_paris \
        --max-images 1000
"""

import argparse
import asyncio
import aiohttp
import csv
import json
import time
from pathlib import Path
from typing import List, Dict, Tuple

class MapillaryDownloader:
    def __init__(self, access_token: str, output_dir: str, max_images: int = 1000):
        self.access_token = access_token
        self.output_dir = Path(output_dir)
        self.max_images = max_images
        self.base_url = "https://graph.mapillary.com"
        
        # Create output directory
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    async def search_images(self, bbox: Tuple[float, float, float, float]) -> List[Dict]:
        """Search for images within bounding box"""
        min_lon, min_lat, max_lon, max_lat = bbox
        
        async with aiohttp.ClientSession() as session:
            images = []
            url = f"{self.base_url}/images"
            params = {
                'access_token': self.access_token,
                'bbox': f"{min_lon},{min_lat},{max_lon},{max_lat}",
                'fields': 'id,thumb_256_url,computed_geometry,captured_at',
                'limit': min(self.max_images, 2000)
            }
            
            print(f"Searching for images in bbox: {bbox}")
            async with session.get(url, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    images = data.get('data', [])
                    print(f"Found {len(images)} images")
                else:
                    print(f"Error searching images: {response.status}")
                    
            return images[:self.max_images]
    
    async def download_image(self, session: aiohttp.ClientSession, image_data: Dict, index: int) -> Dict:
        """Download a single image"""
        try:
            image_id = image_data['id']
            image_url = image_data['thumb_256_url']
            geometry = image_data['computed_geometry']
            
            # Extract coordinates
            if geometry['type'] == 'Point':
                lon, lat = geometry['coordinates']
            else:
                print(f"Skipping non-point geometry: {image_id}")
                return None
            
            # Download image
            filename = f"mapillary_{image_id}_{index:06d}.jpg"
            filepath = self.output_dir / filename
            
            async with session.get(image_url) as response:
                if response.status == 200:
                    with open(filepath, 'wb') as f:
                        f.write(await response.read())
                    
                    return {
                        'image': filename,
                        'lat': lat,
                        'lon': lon,
                        'description': f"Mapillary image {image_id}",
                        'mapillary_id': image_id,
                        'captured_at': image_data.get('captured_at', '')
                    }
                else:
                    print(f"Failed to download {image_id}: {response.status}")
                    return None
                    
        except Exception as e:
            print(f"Error downloading {image_data.get('id', 'unknown')}: {e}")
            return None
    
    async def download_dataset(self, bbox: Tuple[float, float, float, float]):
        """Download complete dataset"""
        print(f"Starting Mapillary download to: {self.output_dir}")
        
        # Search for images
        images = await self.search_images(bbox)
        if not images:
            print("No images found!")
            return
        
        print(f"Downloading {len(images)} images...")
        
        # Download images concurrently
        csv_data = []
        semaphore = asyncio.Semaphore(10)  # Limit concurrent downloads
        
        async def download_with_semaphore(session, image_data, index):
            async with semaphore:
                return await self.download_image(session, image_data, index)
        
        async with aiohttp.ClientSession() as session:
            tasks = [
                download_with_semaphore(session, image_data, i) 
                for i, image_data in enumerate(images)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Collect successful downloads
            for result in results:
                if result and not isinstance(result, Exception):
                    csv_data.append(result)
        
        # Write CSV file
        csv_path = self.output_dir / 'mapillary_dataset.csv'
        with open(csv_path, 'w', newline='') as f:
            if csv_data:
                writer = csv.DictWriter(f, fieldnames=csv_data[0].keys())
                writer.writeheader()
                writer.writerows(csv_data)
        
        print(f"""
=== MAPILLARY DOWNLOAD COMPLETE ===
‚úÖ Downloaded: {len(csv_data)} images
üìÅ Directory: {self.output_dir}
üìÑ CSV file: {csv_path}
üéØ Ready for bulk loading!

Next steps:
python scripts/bulk_loader_production.py \\
    --dataset-dir {self.output_dir} \\
    --source mapillary_dataset \\
    --max-concurrent 8
        """)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Download Mapillary dataset')
    parser.add_argument('--access-token', required=True, help='Mapillary API access token')
    parser.add_argument('--bbox', required=True, help='Bounding box: "min_lon,min_lat,max_lon,max_lat"')
    parser.add_argument('--output-dir', required=True, help='Output directory for dataset')
    parser.add_argument('--max-images', type=int, default=1000, help='Maximum images to download')
    
    args = parser.parse_args()
    
    # Parse bounding box
    bbox_parts = args.bbox.split(',')
    if len(bbox_parts) != 4:
        raise ValueError("Bounding box must be 'min_lon,min_lat,max_lon,max_lat'")
    
    bbox = tuple(float(x) for x in bbox_parts)
    
    downloader = MapillaryDownloader(args.access_token, args.output_dir, args.max_images)
    asyncio.run(downloader.download_dataset(bbox)) 